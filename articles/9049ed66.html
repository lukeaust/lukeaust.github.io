<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Theano简介 | 叶小白</title><meta name="keywords" content="转载,Theano"><meta name="author" content="叶小白"><meta name="copyright" content="叶小白"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="原文地址：https:&#x2F;&#x2F;morvanzhou.github.io&#x2F;tutorials&#x2F;machine-learning&#x2F;theano&#x2F; theano 和 tensorflow 类似，都是基于建立神经网络每个组件，在把组件联系起来，数据放入组件，得到结果。  一、基本用法  首先, 需要加载 theano 和 numpy 两个模块, 并且使用 theano 来创建 function  import">
<meta property="og:type" content="article">
<meta property="og:title" content="Theano简介">
<meta property="og:url" content="https://lukeaust.github.io/articles/9049ed66.html">
<meta property="og:site_name" content="叶小白">
<meta property="og:description" content="原文地址：https:&#x2F;&#x2F;morvanzhou.github.io&#x2F;tutorials&#x2F;machine-learning&#x2F;theano&#x2F; theano 和 tensorflow 类似，都是基于建立神经网络每个组件，在把组件联系起来，数据放入组件，得到结果。  一、基本用法  首先, 需要加载 theano 和 numpy 两个模块, 并且使用 theano 来创建 function  import">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/lukeaust/blog/img/fairy.jpg">
<meta property="article:published_time" content="2020-07-03T09:25:00.000Z">
<meta property="article:modified_time" content="2021-06-29T07:50:09.000Z">
<meta property="article:author" content="叶小白">
<meta property="article:tag" content="转载">
<meta property="article:tag" content="Theano">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/lukeaust/blog/img/fairy.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://lukeaust.github.io/articles/9049ed66"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?effc5e1b8b82b656e64a5c2817817fc2";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'mediumZoom',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Theano简介',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-06-29 15:50:09'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="叶小白" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">48</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">47</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E8%AE%BA%E6%96%87%E6%91%98%E8%A6%81/"><i class="fa-fw fas fa-thumbs-up"></i><span> 论文摘要</span></a></li><li><a class="site-page child" href="/categories/%E8%AE%BA%E6%96%87%E5%93%81%E8%AF%BB/"><i class="fa-fw fas fa-book"></i><span> 论文品读</span></a></li><li><a class="site-page child" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><i class="fa-fw fas fa-ship"></i><span> 深度学习</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/files/nav.html"><i class="fa-fw fas fa-link"></i><span> 导航</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/lukeaust/blog/img/fairy.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">叶小白</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E8%AE%BA%E6%96%87%E6%91%98%E8%A6%81/"><i class="fa-fw fas fa-thumbs-up"></i><span> 论文摘要</span></a></li><li><a class="site-page child" href="/categories/%E8%AE%BA%E6%96%87%E5%93%81%E8%AF%BB/"><i class="fa-fw fas fa-book"></i><span> 论文品读</span></a></li><li><a class="site-page child" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><i class="fa-fw fas fa-ship"></i><span> 深度学习</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/files/nav.html"><i class="fa-fw fas fa-link"></i><span> 导航</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Theano简介</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-07-03T09:25:00.000Z" title="发表于 2020-07-03 17:25:00">2020-07-03</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-06-29T07:50:09.000Z" title="更新于 2021-06-29 15:50:09">2021-06-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Theano/">Theano</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>26分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Theano简介"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>原文地址：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://morvanzhou.github.io/tutorials/machine-learning/theano/">https://morvanzhou.github.io/tutorials/machine-learning/theano/</a></p>
<p>theano 和 tensorflow 类似，都是基于建立神经网络每个组件，在把组件联系起来，数据放入组件，得到结果。</p>
<h2 id="一-基本用法"><a class="markdownIt-Anchor" href="#一-基本用法"></a> 一、基本用法</h2>
<ol>
<li>首先, 需要加载 theano 和 numpy 两个模块, 并且使用 theano 来创建 function</li>
</ol>
<pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> theano.tensor <span class="hljs-keyword">as</span> T
<span class="hljs-keyword">from</span> theano <span class="hljs-keyword">import</span> function
</code></pre>
<ol start="2">
<li>定义X和Y两个常量 (scalar)，把结构建立好之后，把结构放在function，在把数据放在function。</li>
</ol>
<pre class="highlight"><code class="python"><span class="hljs-comment"># basic</span>
x = T.dscalar(<span class="hljs-string">'x'</span>)  <span class="hljs-comment"># 建立 x 的容器</span>
y = T.dscalar(<span class="hljs-string">'y'</span>)  <span class="hljs-comment"># 建立 y 的容器</span>
z = x+y     <span class="hljs-comment">#  建立方程</span>

<span class="hljs-comment"># 使用 function 定义 theano 的方程, </span>
<span class="hljs-comment"># 将输入值 x, y 放在 [] 里,  输出值 z 放在后面</span>
f = function([x, y], z)  

print(f(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>))  <span class="hljs-comment"># 将确切的 x, y 值放入方程中</span>
<span class="hljs-comment"># 5.0</span>

<span class="hljs-keyword">from</span> theano <span class="hljs-keyword">import</span> pp
print(pp(z)) <span class="hljs-comment">#  pp (pretty-print) 打印原始方程</span>
<span class="hljs-comment"># (x + y)</span>
</code></pre>
<pre><code>5.0
(x + y)
</code></pre>
<ol start="3">
<li>定义矩阵，以及利用矩阵做相关运算:</li>
</ol>
<pre class="highlight"><code class="python">x = T.dmatrix(<span class="hljs-string">'x'</span>)  <span class="hljs-comment"># 矩阵 x 的容器</span>
y = T.dmatrix(<span class="hljs-string">'y'</span>)  <span class="hljs-comment"># 矩阵 y 的容器</span>
z = x + y   <span class="hljs-comment"># 定义矩阵加法</span>
f = function([x, y], z) <span class="hljs-comment"># 定义方程</span>

print(f(
    np.arange(<span class="hljs-number">12</span>).reshape((<span class="hljs-number">3</span>,<span class="hljs-number">4</span>)), <span class="hljs-comment"># x </span>
    <span class="hljs-number">10</span>*np.ones((<span class="hljs-number">3</span>,<span class="hljs-number">4</span>)) <span class="hljs-comment"># y</span>
    )
  )
</code></pre>
<pre><code>[[10. 11. 12. 13.]
 [14. 15. 16. 17.]
 [18. 19. 20. 21.]]
</code></pre>
<hr />
<h2 id="二-function用法"><a class="markdownIt-Anchor" href="#二-function用法"></a> 二、Function用法</h2>
<pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> theano.tensor <span class="hljs-keyword">as</span> T
<span class="hljs-keyword">import</span> theano
</code></pre>
<p>theano 当中的 function 就和 python 中的 function 类似, 不过因为要被用在多进程并行运算中,所以他的 function 有他自己的一套使用方式.<br />
以下介绍function的三种用法，并且各举一个例子。</p>
<h3 id="1-激励活函数例子activation-function"><a class="markdownIt-Anchor" href="#1-激励活函数例子activation-function"></a> 1. 激励/活函数例子(activation function)</h3>
<p>深度学习的基本原理是基于人工神经网络，信号从一个神经元进入，经过非线性的activation function，传入到下一层神经元；再经过该层神经元的activate，继续往下传递，如此循环往复，直到输出层。激励函数一般用于神经网络的层与层之间，上一层的输出通过激励函数的转换之后输入到下一层中。神经网络模型是非线性的，如果没有使用激励函数，那么每一层实际上都相当于矩阵相乘。经过非线性的激励函数作用，使得神经网络有了更多的表现力。</p>
<pre class="highlight"><code class="python"><span class="hljs-comment"># 1. 首先需要定义一个 tensor T:</span>
x=T.dmatrix(<span class="hljs-string">'x'</span>)
<span class="hljs-comment"># 2. 声明概率计算方法（要用Theano里面的计算方式）</span>
s=<span class="hljs-number">1</span>/(<span class="hljs-number">1</span>+T.exp(-x)) <span class="hljs-comment"># logistic or soft step </span>
<span class="hljs-comment"># 3. 调用theano定义的计算函数logistic</span>
logistic=theano.function([x],s)

print(logistic([[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">-2</span>,<span class="hljs-number">-3</span>]]))
</code></pre>
<pre><code>[[0.5        0.73105858]
 [0.11920292 0.04742587]]
</code></pre>
<h3 id="2-多输入输出的-function"><a class="markdownIt-Anchor" href="#2-多输入输出的-function"></a> 2. 多输入/输出的 function</h3>
<p>假定我们的 theano 函数中的输入值是两个，输出也是两个。 指定输入的值是矩阵a,b</p>
<pre class="highlight"><code class="python">a,b=T.dmatrices(<span class="hljs-string">'a'</span>,<span class="hljs-string">'b'</span>)

diff=a-b <span class="hljs-comment"># 差（diff）</span>
abs_diff=abs(diff) <span class="hljs-comment"># 差的绝对值（abs_diff）</span>
diff_squared=diff**<span class="hljs-number">2</span> <span class="hljs-comment"># 差的平方（diff_squared）</span>

f=theano.function([a,b],[diff,abs_diff,diff_squared]) <span class="hljs-comment"># 两个输入，三个输出</span>
</code></pre>
<p>调用函数f, 并且向函数传递初始化之后的参数</p>
<pre class="highlight"><code class="python">x1,x2,x3=f( <span class="hljs-comment"># x1,x2,x3分别对应三个输出值</span>
    np.ones((<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)), <span class="hljs-comment"># a</span>
    np.arange(<span class="hljs-number">4</span>).reshape((<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)) <span class="hljs-comment"># b</span>
)
print(x1,<span class="hljs-string">'\n\n'</span>,x2,<span class="hljs-string">'\n\n'</span>,x3)
</code></pre>
<pre><code>[[ 1.  0.]
 [-1. -2.]] 

 [[1. 0.]
 [1. 2.]] 

 [[1. 0.]
 [1. 4.]]
</code></pre>
<h3 id="3-function的默认值及指定参数名"><a class="markdownIt-Anchor" href="#3-function的默认值及指定参数名"></a> 3. function的默认值及指定参数名</h3>
<p>首先，使用 T.dscalars() 同时定义三个标量的容器以及输出值z</p>
<pre class="highlight"><code class="python">x,y,w = T.dscalars(<span class="hljs-string">'x'</span>,<span class="hljs-string">'y'</span>,<span class="hljs-string">'w'</span>)
z = (x+y)*w
</code></pre>
<p>（1）使用 theano 的<strong>默认值书写方式</strong>指定参数的默认值</p>
<pre class="highlight"><code class="python">f = theano.function( [x, theano.In(y,value=<span class="hljs-number">1</span>), theano.In(w,value=<span class="hljs-number">2</span>)], z) <span class="hljs-comment"># In是什么函数？</span>


print(f(<span class="hljs-number">23</span>))    <span class="hljs-comment"># 使用默认</span>
print(f(<span class="hljs-number">23</span>,<span class="hljs-number">1</span>,<span class="hljs-number">4</span>)) <span class="hljs-comment"># 不使用默认</span>
</code></pre>
<pre><code>48.0
96.0
</code></pre>
<p>（2）还可以在定义默认值的时候，可以<strong>指定参数名字</strong>。 这样做的目的是防止我们定义的参数过于多的情况下，忘记函数的顺序。</p>
<pre class="highlight"><code class="python">f = theano.function([x,
                     theano.In(y, value=<span class="hljs-number">1</span>),
                     theano.In(w,value=<span class="hljs-number">2</span>,name=<span class="hljs-string">'weights'</span>)],
                    z)
                    
<span class="hljs-keyword">print</span> (f(<span class="hljs-number">23</span>,<span class="hljs-number">1</span>,weights=<span class="hljs-number">4</span>)) <span class="hljs-comment">##调用方式</span>
</code></pre>
<pre><code>96.0
</code></pre>
<hr />
<h2 id="三-shared变量"><a class="markdownIt-Anchor" href="#三-shared变量"></a> 三、Shared变量</h2>
<pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> theano
<span class="hljs-keyword">import</span> theano.tensor <span class="hljs-keyword">as</span> T
</code></pre>
<p>Shared 变量，意思是这些变量可以在运算过程中，不停地进行交换和更新值。 在定义 weights 和 bias 的情况下，会需要用到这样的变量。</p>
<h3 id="1-定义shared变量"><a class="markdownIt-Anchor" href="#1-定义shared变量"></a> 1. 定义Shared变量</h3>
<p>用累加器来定义 Shared 变量，每一次向上面加一个值，每一次基于上面的变化，再加上另一个值，就这样不断地更新并保存这样的值。</p>
<p>用 np.array 给它赋予初始值，初始值是 0，并且它的<strong>数据类型</strong>要规定好。 数据类型是很重要的，在后面要定义 vector 或者 matrix 的时候，一定要<strong>统一</strong>，否则就会报错。 这个例子中，我们定义它为 float64，所以在后面定义其他结构的时候，也要保证这样的数据类型。 最后一个参数就是它的<strong>名字</strong> ‘state’。</p>
<pre class="highlight"><code class="python">state=theano.shared(np.array(<span class="hljs-number">0</span>,dtype=np.float64),<span class="hljs-string">'state'</span>)
</code></pre>
<p>下面是累加值，定义它的名字为 inc，还有它的数据类型，调用 state.dtype，而不是写 dtype=np.float64， 否则会报错。</p>
<pre class="highlight"><code class="python">inc=T.scalar(<span class="hljs-string">'inc'</span>,dtype=state.dtype)
</code></pre>
<p>接下来是要定义一个 accumulator 函数，它的输入参数为 inc，结果就是输出 state，累加的过程叫做 updates，就是要把现在的 state 变成 state+inc 。</p>
<pre class="highlight"><code class="python">accumulator=theano.function([inc],state,updates=[(state,state+inc)])
</code></pre>
<h3 id="2-提取使用"><a class="markdownIt-Anchor" href="#2-提取使用"></a> 2. 提取使用</h3>
<p>打印： 不能直接用 print(accumulator(10))，因为这样输出的，第一次就是初始值 0，只能到下一次输出的时候，才会出现 10. 下面这个更科学，它可以取出 state 的当前值，我们可以先后 ＋1， ＋10， 打印结果看看如何</p>
<p>即，先调用后输出</p>
<pre class="highlight"><code class="python"><span class="hljs-comment"># to get variable value</span>
print(state.get_value())
<span class="hljs-comment"># 0.0</span>

accumulator(<span class="hljs-number">1</span>)   <span class="hljs-comment"># return previous value, 0 in here</span>
print(state.get_value())
<span class="hljs-comment"># 1.0</span>

accumulator(<span class="hljs-number">10</span>)  <span class="hljs-comment"># return previous value, 1 in here</span>
print(state.get_value())
<span class="hljs-comment"># 11.0</span>
</code></pre>
<pre><code>0.0
1.0
11.0
</code></pre>
<p>而 set_value 可以用来重新设置参数，例如 把 11 变成了 －1，那么再 ＋3 之后就是 2，而不是 11+3=14.</p>
<pre class="highlight"><code class="python"><span class="hljs-comment"># to set variable value</span>
state.set_value(<span class="hljs-number">-1</span>)
accumulator(<span class="hljs-number">3</span>)
print(state.get_value())
<span class="hljs-comment"># 2.0</span>
</code></pre>
<pre><code>2.0
</code></pre>
<p><strong>get_value， set_value 这两种只能在 Shared 变量 的时候调用。</strong></p>
<h3 id="3-临时使用"><a class="markdownIt-Anchor" href="#3-临时使用"></a> 3. 临时使用</h3>
<p>有时只是想暂时使用 Shared 变量，并不需要把它更新： 这时我们可以定义一个 a 来临时代替 state，注意定义 a 的时候也要统一 dtype。</p>
<pre class="highlight"><code class="">a = T.scalar(dtype=state.dtype)
</code></pre>
<p>然后忽略掉 Shared 变量 的运算，输入值是 [inc, a]，相当于把 a 代入 state，输出是 tmp_func，givens 就是想把什么替换成什么。 这样的话，在调用 skip_shared 函数后，state 并没有被改变。</p>
<pre class="highlight"><code class="python"><span class="hljs-comment"># temporarily replace shared variable with another value in another function</span>
tmp_func = state * <span class="hljs-number">2</span> + inc
a = T.scalar(dtype=state.dtype)
skip_shared = theano.function([inc, a], tmp_func, givens=[(state, a)]) <span class="hljs-comment"># temporarily use a's value for the state</span>
print(skip_shared(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))
<span class="hljs-comment"># 8.0</span>

print(state.get_value()) <span class="hljs-comment"># old state value</span>
<span class="hljs-comment"># 2.0</span>
</code></pre>
<pre><code>8.0
2.0
</code></pre>
<hr />
<h2 id="四-layer类"><a class="markdownIt-Anchor" href="#四-layer类"></a> 四、Layer类</h2>
<h3 id="1-准备"><a class="markdownIt-Anchor" href="#1-准备"></a> 1. 准备</h3>
<pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> theano
<span class="hljs-keyword">import</span> theano.tensor <span class="hljs-keyword">as</span> T
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
</code></pre>
<p>定义一个具有两层神经元的神经网络</p>
<pre class="highlight"><code class="python">l1=Layer(inputs,<span class="hljs-number">1</span>,<span class="hljs-number">10</span>,T.nnet.relu)
l2=Layer(l1,outputs,<span class="hljs-number">10</span>,<span class="hljs-literal">None</span>)
</code></pre>
<h3 id="2-定义层结构"><a class="markdownIt-Anchor" href="#2-定义层结构"></a> 2. 定义层结构</h3>
<pre class="highlight"><code class="python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Layer</span><span class="hljs-params">(object)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, inputs, in_size, out_size, activation_function=None)</span>:</span>
        self.W = theano.shared(np.random.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, (in_size, out_size)))
        self.b = theano.shared(np.zeros((out_size, )) + <span class="hljs-number">0.1</span>)
        self.Wx_plus_b = T.dot(inputs, self.W) + self.b
        self.activation_function = activation_function
        <span class="hljs-keyword">if</span> activation_function <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
            self.outputs = self.Wx_plus_b
        <span class="hljs-keyword">else</span>:
            self.outputs = self.activation_function(self.Wx_plus_b)
</code></pre>
<h3 id="3-细节说明"><a class="markdownIt-Anchor" href="#3-细节说明"></a> 3. 细节说明</h3>
<p>这段代码中，我们最关心的就是这个类的<strong>构造函数</strong></p>
<pre class="highlight"><code class="">def __init__(self, inputs, in_size, out_size, activation_function=None)
</code></pre>
<p>和之前的例子一致，我们采用了相同的输入变量名。</p>
<p>接着，我们定义了W,b来代表该神经网络层的<strong>输入权值和偏置值</strong>，我们把W初始化为由符合均值为0， 方差为1<strong>高斯分布</strong>的随机变量值组成的<code>in_size-by-out_size</code>的矩阵; b初始化为值为0.1的<code>out_put-by-1</code>的向量。 (当然，我们也可以采用不同的初始化方法，这里我们暂时不讨论初始化权值对最终神经网络训练的影响)。</p>
<pre class="highlight"><code class="">self.W = theano.shared(np.random.normal(0, 1, (in_size, out_size)))
self.b = theano.shared(np.zeros((out_size, )) + 0.1)
</code></pre>
<p>首先我们要计算所有神经元的<strong>输入矩阵</strong>, 也就是输入inputs与输入权值W的点乘（dot product）再<strong>加上偏置值b</strong>：</p>
<pre class="highlight"><code class="">self.Wx_plus_b = T.dot(inputs, self.W) + self.b
</code></pre>
<p>然后，我们需要根据我们构造神经层指定的<strong>激活函数类型</strong><code>activation_function</code>,来计算神经层的输出向量。 这里我们假设如果<code>activation_function</code>是None， 那就是该层神经元采用线形输出；如果是其他Theano的激活函数，就把<code>Wx_plus_b</code>作为该层激活函数的输入，同时函数的输出即为神经层的输出：</p>
<pre class="highlight"><code class="">self.activation_function = activation_function
if activation_function is None:
	self.outputs = self.Wx_plus_b
else:
	self.outputs = self.activation_function(self.Wx_plus_b)
</code></pre>
<p>我们就成功的定义了神经网络的最最重要的结构–<strong>神经层Layer</strong>。</p>
<hr />
<h2 id="五-回归例子regression"><a class="markdownIt-Anchor" href="#五-回归例子regression"></a> 五、回归例子Regression</h2>
<h3 id="1-导入模块"><a class="markdownIt-Anchor" href="#1-导入模块"></a> 1. 导入模块</h3>
<pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> theano
<span class="hljs-keyword">import</span> theano.tensor <span class="hljs-keyword">as</span> T
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
</code></pre>
<h3 id="2-定义层结构-2"><a class="markdownIt-Anchor" href="#2-定义层结构-2"></a> 2. 定义层结构</h3>
<pre class="highlight"><code class="python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Layer</span><span class="hljs-params">(object)</span>:</span>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,inputs,in_size,out_size,activation_function=None)</span>:</span>
    self.W=theano.shared(np.random.normal(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,(in_size,out_size)))
    self.b=theano.shared(np.zeros((out_size,))+<span class="hljs-number">0.1</span>)
    self.Wx_plus_b=T.dot(inputs,self.W)+self.b
    self.activation_function=activation_function
    <span class="hljs-keyword">if</span> activation_function <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
      self.outputs=self.Wx_plus_b
    <span class="hljs-keyword">else</span>:
      self.outputs=self.activation_function(self.Wx_plus_b)
</code></pre>
<h3 id="3-准备数据集"><a class="markdownIt-Anchor" href="#3-准备数据集"></a> 3. 准备数据集</h3>
<p>构造一组x、y，其中y的值都是对应的函数值接近的数值。即<code>y = x^2 - 0.5 + noise</code></p>
<pre class="highlight"><code class="python">x_data=np.linspace(<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">300</span>)[:,np.newaxis] <span class="hljs-comment"># 生成-1到1之间均匀间隔的300个数，再扩充为二维</span>
noise=np.random.normal(<span class="hljs-number">0</span>,<span class="hljs-number">0.05</span>,x_data.shape)
y_data=np.square(x_data)<span class="hljs-number">-0.5</span>+noise
</code></pre>
<pre class="highlight"><code class="python">plt.scatter(x_data,y_data)
plt.show()
</code></pre>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/articles/9049ed66/output_69_0.png" class="">
<h3 id="4-搭建网络"><a class="markdownIt-Anchor" href="#4-搭建网络"></a> 4. 搭建网络</h3>
<p>(1) 定义神经网络的输入和目标</p>
<pre class="highlight"><code class="python">x=T.dmatrix(<span class="hljs-string">'x'</span>)
y=T.dmatrix(<span class="hljs-string">'y'</span>)
</code></pre>
<p>(2) 设计神经网络</p>
<pre class="highlight"><code class="python">l1 = Layer(x, <span class="hljs-number">1</span>, <span class="hljs-number">10</span>, T.nnet.relu)
l2 = Layer(l1.outputs, <span class="hljs-number">10</span>, <span class="hljs-number">1</span>, <span class="hljs-literal">None</span>)
</code></pre>
<p>(3) 定义损失函数</p>
<pre class="highlight"><code class="python">cost=T.mean(T.square(l2.outputs-y))
</code></pre>
<p>(4) 计算神经网络权值和偏置值的梯度</p>
<pre class="highlight"><code class="python">gW1,gb1,gW2,gb2=T.grad(cost,[l1.W,l1.b,l2.W,l2.b])
</code></pre>
<p>(5) 定义一个学习率</p>
<pre class="highlight"><code class="python">learning_rate=<span class="hljs-number">0.05</span>
</code></pre>
<p>(6) 描述训练过程</p>
<pre class="highlight"><code class="python">train=theano.function(
    inputs=[x,y],
    outputs=cost,
    updates=[(l1.W,l1.W-learning_rate*gW1),
        (l1.b,l1.b-learning_rate*gb1),
        (l2.W,l2.W-learning_rate*gW2),
        (l2.b,l2.b-learning_rate*gb2)
    ]
)
</code></pre>
<pre><code>WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
</code></pre>
<p>(7) 定义一个预测函数</p>
<pre class="highlight"><code class="python">predict=theano.function(inputs=[x],outputs=l2.outputs)
</code></pre>
<h3 id="5-开始训练"><a class="markdownIt-Anchor" href="#5-开始训练"></a> 5. 开始训练</h3>
<pre class="highlight"><code class="python"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1000</span>):
  err=train(x_data,y_data)
  <span class="hljs-keyword">if</span> i % <span class="hljs-number">50</span>==<span class="hljs-number">0</span>:
    print(err)
</code></pre>
<pre><code>1.7817381967261003
0.03900273780119691
0.01705260292529913
0.008857913877541073
0.007628401545243699
0.007154872218835795
0.006845074417545497
0.006603734725625393
0.006393439520042726
0.006211410026813022
0.00604399098088469
0.005888642078912878
0.005751130914528592
0.005627157029312892
0.005515948932985979
0.005409217763685208
0.005315212511973516
0.0052381625906053695
0.005167258521000119
0.005103197798244597
</code></pre>
<h3 id="6-可视化"><a class="markdownIt-Anchor" href="#6-可视化"></a> 6. 可视化</h3>
<pre class="highlight"><code class="python"><span class="hljs-comment"># plot the real data</span>
fig = plt.figure()
ax = fig.add_subplot(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)
ax.scatter(x_data, y_data)
plt.ion()
plt.show()

<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1000</span>):
    <span class="hljs-comment"># training</span>
    err = train(x_data, y_data)
    <span class="hljs-keyword">if</span> i % <span class="hljs-number">50</span> == <span class="hljs-number">0</span>:
        <span class="hljs-comment"># to visualize the result and improvement</span>
        <span class="hljs-keyword">try</span>:
            ax.lines.remove(lines[<span class="hljs-number">0</span>])
        <span class="hljs-keyword">except</span> Exception:
            <span class="hljs-keyword">pass</span>
        prediction_value = predict(x_data)
        <span class="hljs-comment"># plot the prediction</span>
        lines = ax.plot(x_data, prediction_value, <span class="hljs-string">'r-'</span>, lw=<span class="hljs-number">5</span>)
        plt.pause(<span class="hljs-number">.5</span>)


<span class="hljs-comment"># 只显示最后结果</span>
<span class="hljs-comment"># for i in range(1000):</span>
<span class="hljs-comment">#     # training</span>
<span class="hljs-comment">#     err = train(x_data, y_data)</span>
     
<span class="hljs-comment"># prediction_value = predict(x_data)</span>
<span class="hljs-comment"># # plot the prediction</span>
<span class="hljs-comment"># lines = ax.plot(x_data, prediction_value, 'r-', lw=5)</span>
</code></pre>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/articles/9049ed66/output_88_0.png" class="">
<hr />
<h2 id="六-分类学习"><a class="markdownIt-Anchor" href="#六-分类学习"></a> 六、分类学习</h2>
<h3 id="1-导入模块-2"><a class="markdownIt-Anchor" href="#1-导入模块-2"></a> 1. 导入模块</h3>
<pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> theano
<span class="hljs-keyword">import</span> theano.tensor <span class="hljs-keyword">as</span> T
</code></pre>
<h3 id="2-定义函数"><a class="markdownIt-Anchor" href="#2-定义函数"></a> 2. 定义函数</h3>
<p>先定义一个功能，用来计算分类问题的准确率，即预测的类别中有多少是和实际类别一样的，计算出百分比</p>
<pre class="highlight"><code class="python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">compute_accuracy</span><span class="hljs-params">(y_target,y_predict)</span>:</span>
  correct_prediction=np.equal(y_predict,y_target)
  accuracy=np.sum(correct_prediction)/len(correct_prediction)
  <span class="hljs-keyword">return</span> accuracy
</code></pre>
<h3 id="3-准备数据集-2"><a class="markdownIt-Anchor" href="#3-准备数据集-2"></a> 3. 准备数据集</h3>
<p>用<code>randn</code>随机生成数据集。D中的<code>input_values</code>是400个样本，784个feature。<code>target_class</code>是有两类，0和1。要做的是，用神经网络训练数据学习哪些输入对应0，哪些对应1.</p>
<pre class="highlight"><code class="python">rng=np.random

N=<span class="hljs-number">400</span> <span class="hljs-comment"># training 数据个数</span>
feats=<span class="hljs-number">784</span>  <span class="hljs-comment"># input 的 feature 数</span>

<span class="hljs-comment"># 生成随机数: D = (input_values, target_class)</span>
input_values=rng.randn(N,feats)
target_class=rng.randint(size=N,low=<span class="hljs-number">0</span>,high=<span class="hljs-number">2</span>)
D=(input_values,target_class)
print(input_values.shape,target_class.shape)
</code></pre>
<pre><code>(400, 784) (400,)
</code></pre>
<h3 id="4-建立模型"><a class="markdownIt-Anchor" href="#4-建立模型"></a> 4. 建立模型</h3>
<p>(1)定义x和y容器</p>
<pre class="highlight"><code class="python"><span class="hljs-comment"># 定义x、y容器</span>
x=T.dmatrices(<span class="hljs-string">"x"</span>)
y=T.dvector(<span class="hljs-string">"y"</span>)
</code></pre>
<p>(2)初始化<code>weights</code>和<code>bias</code></p>
<p>有多少<code>features</code>就生成多少个<code>weights</code></p>
<pre class="highlight"><code class="python">W=theano.shared(rng.randn(feats),name=<span class="hljs-string">"w"</span>)
b=theano.shared(<span class="hljs-number">0.</span>,name=<span class="hljs-string">"b"</span>)
</code></pre>
<pre><code>w b
</code></pre>
<p>(3) 定义激励函数、交叉熵</p>
<p><code>p_1</code>是用<code>sigmoid</code>求的概率，输入越小，则概率值越接近0，越大则越接近1，等于0则值为0.5. <code>p_1 &gt; 0.5</code>时，预测值为True，即为1。然后计算针对每个<code>sample</code>的交叉熵<code>xent</code>。 再计算整批数据的<code>cost</code>，为了减小<code>overfitting</code>，这里加入了<code>L1-正则化</code>。接下来可以计算<code>weights</code>和<code>bias</code>的梯度<code>gW,gb</code>。</p>
<pre class="highlight"><code class="python">p_1 = T.nnet.sigmoid(T.dot(x, W) + b)   <span class="hljs-comment"># sigmoid 激励函数</span>
prediction = p_1 &gt; <span class="hljs-number">0.5</span>                  
xent = -y * T.log(p_1) - (<span class="hljs-number">1</span>-y) * T.log(<span class="hljs-number">1</span>-p_1) <span class="hljs-comment"># 交叉熵</span>

<span class="hljs-comment"># xent 也可以使用下面这个达到一样的效果</span>
<span class="hljs-comment"># xent = T.nnet.binary_crossentropy(p_1, y) </span>

cost = xent.mean() + <span class="hljs-number">0.01</span> * (W ** <span class="hljs-number">2</span>).sum()  <span class="hljs-comment"># l2 正则化</span>
gW, gb = T.grad(cost, [W, b])      
</code></pre>
<h3 id="5-激活模型"><a class="markdownIt-Anchor" href="#5-激活模型"></a> 5. 激活模型</h3>
<p>学习率需要小于 1. 接下来定义两个函数 train 和 predict，方法和上一节课的类似。 outputs 可以输出两个 prediction 和交叉熵损失的平均值 xent.mean。</p>
<pre class="highlight"><code class="python">learning_rate = <span class="hljs-number">0.1</span>
train = theano.function(
          inputs=[x, y],
          outputs=[prediction, xent.mean()],
          updates=((W, W - learning_rate * gW), (b, b - learning_rate * gb)))
predict = theano.function(inputs=[x], outputs=prediction)
</code></pre>
<pre><code>WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
</code></pre>
<h3 id="6-训练模型"><a class="markdownIt-Anchor" href="#6-训练模型"></a> 6. 训练模型</h3>
<p>用训练集的 feature 和 target 训练模型，输出预测值和损失 pred, err。 每 50 步打印一次损失和准确率。</p>
<pre class="highlight"><code class="python"><span class="hljs-comment"># Training</span>
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">500</span>):
    pred, err = train(D[<span class="hljs-number">0</span>], D[<span class="hljs-number">1</span>])
    <span class="hljs-keyword">if</span> i % <span class="hljs-number">50</span> == <span class="hljs-number">0</span>:
        print(<span class="hljs-string">'cost:'</span>, err)
        print(<span class="hljs-string">"accuracy:"</span>, compute_accuracy(D[<span class="hljs-number">1</span>], predict(D[<span class="hljs-number">0</span>])))
</code></pre>
<pre><code>cost: 12.553807719422512
accuracy: 0.4775
cost: 6.726440247644676
accuracy: 0.5725
cost: 3.171624657015871
accuracy: 0.6925
cost: 1.350026797131612
accuracy: 0.82
cost: 0.5344876981014164
accuracy: 0.92
cost: 0.20028190520309347
accuracy: 0.9775
cost: 0.12085672355644826
accuracy: 0.995
cost: 0.08779645850799486
accuracy: 0.9975
cost: 0.06446280613696766
accuracy: 0.9975
cost: 0.04648645334444508
accuracy: 0.9975
</code></pre>
<p>最后打印出预测值与实际值进行比较</p>
<pre class="highlight"><code class="python">print(<span class="hljs-string">"target values for D:"</span>)
print(D[<span class="hljs-number">1</span>])
print(<span class="hljs-string">"prediction on D:"</span>)
print(predict(D[<span class="hljs-number">0</span>]))
</code></pre>
<pre><code>target values for D:
[0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1
 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 0 1 0
 1 1 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 1 1
 1 1 0 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0
 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0
 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0
 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0 1 0 1
 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 0 0 0 1 0 0 1 0
 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 0 0 1
 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0
 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1 1 1 0 1 0 0]
prediction on D:
[False  True  True False  True  True False  True  True  True False  True
  True  True  True  True False  True False False False False False  True
 False False False False  True  True  True False False  True  True False
  True False  True False False  True  True False False False  True  True
 False False False False False  True False False False False False False
  True  True False False  True False  True  True False False False False
  True False  True  True False  True False  True  True  True  True  True
 False False  True False False  True False False  True False  True False
  True False False  True  True False  True False  True False False False
 False  True  True  True  True False False  True  True False  True False
 False False  True  True False False  True False False False  True False
 False  True False  True False False False False  True  True False False
 False  True  True False False False False  True  True False  True False
 False  True False  True False False False  True False  True  True  True
 False False  True  True False False False False False False  True False
 False  True  True False False False False False False False False False
 False  True False  True False  True  True False  True False False  True
 False False  True  True False  True False False False  True False  True
  True False False False False False False False  True  True False  True
  True  True  True False False  True  True False False False  True  True
  True False False  True  True False  True  True  True False False  True
 False False  True False  True False  True False  True False False False
  True False  True False  True False False False False  True  True  True
 False False  True  True  True  True False  True  True  True  True False
 False False False  True False False  True False False  True  True False
 False False  True False  True  True False False  True False False False
 False  True  True False False  True  True False  True False  True  True
 False  True False  True  True False False False  True  True  True False
  True  True  True  True  True  True  True  True  True False False  True
  True False False False  True  True False False False False  True  True
 False  True False False False False False  True  True False  True  True
 False False False False False  True False  True False False False  True
 False  True False False False False  True False False  True  True  True
 False  True False False]
</code></pre>
<hr />
<h2 id="七-正则化"><a class="markdownIt-Anchor" href="#七-正则化"></a> 七、正则化</h2>
<p>在用机器学习模型时，会把数据集分为<strong>训练集</strong>和<strong>测试集</strong>，训练集用来学习模型，测试集相当于新数据，用来检验模型的效果。</p>
<p>如果对于训练集，学习的效果非常好，甚至接近完美地穿过每个点，或者非常准确地进行了分类，但是当把这个模型<strong>应用于新的数据集上，表现却特别差</strong>，这种现象就叫***过拟合***。</p>
<p>所以在实际运用时要尽量减小 overfitting。常用的方法有 L1，L2 <strong>正则化</strong>。</p>
<h3 id="1-导入模块并导入数据"><a class="markdownIt-Anchor" href="#1-导入模块并导入数据"></a> 1. 导入模块并导入数据</h3>
<pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> theano
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_boston
<span class="hljs-keyword">import</span> theano.tensor <span class="hljs-keyword">as</span> T
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
</code></pre>
<p>数据用的是 load_boston 房价数据，有 500 多个样本，13 个 feature，每个样本对应一个房价。 其中 y 通过增加维度 [:, np.newaxis] 由列表结构变成了矩阵的形式。</p>
<pre class="highlight"><code class="python"><span class="hljs-comment"># 定义数据归一化函数</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">minmax_normalization</span><span class="hljs-params">(data)</span>:</span> 
    xs_max = np.max(data, axis=<span class="hljs-number">0</span>)
    xs_min = np.min(data, axis=<span class="hljs-number">0</span>)
    xs = (<span class="hljs-number">1</span> - <span class="hljs-number">0</span>) * (data - xs_min) / (xs_max - xs_min) + <span class="hljs-number">0</span>
    <span class="hljs-keyword">return</span> xs
<span class="hljs-comment"># 加载数据</span>
np.random.seed(<span class="hljs-number">100</span>)
x_data = load_boston().data
<span class="hljs-comment"># minmax normalization, rescale the inputs</span>
x_data = minmax_normalization(x_data)
y_data = load_boston().target[:, np.newaxis]

<span class="hljs-comment"># 把数据集分为训练集和测试集</span>
x_train, y_train = x_data[:<span class="hljs-number">400</span>], y_data[:<span class="hljs-number">400</span>]
x_test, y_test = x_data[<span class="hljs-number">400</span>:], y_data[<span class="hljs-number">400</span>:]

x = T.dmatrix(<span class="hljs-string">"x"</span>)
y = T.dmatrix(<span class="hljs-string">"y"</span>)
</code></pre>
<h3 id="2-建立模型"><a class="markdownIt-Anchor" href="#2-建立模型"></a> 2. 建立模型</h3>
<p>建立两个神经层，l1 有 13 个属性，50 个神经元，激活函数是 T.tanh。 l2 的输入值为前一层的输出，有 50 个，输出值为房价，只有 1 个</p>
<pre class="highlight"><code class="python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Layer</span><span class="hljs-params">(object)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, inputs, in_size, out_size, activation_function=None)</span>:</span>
        self.W = theano.shared(np.random.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, (in_size, out_size)))
        self.b = theano.shared(np.zeros((out_size, )) + <span class="hljs-number">0.1</span>)
        self.Wx_plus_b = T.dot(inputs, self.W) + self.b
        self.activation_function = activation_function
        <span class="hljs-keyword">if</span> activation_function <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
            self.outputs = self.Wx_plus_b
        <span class="hljs-keyword">else</span>:
            self.outputs = self.activation_function(self.Wx_plus_b)
</code></pre>
<pre class="highlight"><code class="python">l1=Layer(x,<span class="hljs-number">13</span>,<span class="hljs-number">50</span>,T.tanh)
l2=Layer(l1.outputs,<span class="hljs-number">50</span>,<span class="hljs-number">1</span>,<span class="hljs-literal">None</span>)
</code></pre>
<p>计算 cost，第一种表达式是没有正则化的时候，会发现 overfitting 的现象。 第二种是加入 L2 正则化的表达，即把所有神经层的所有 weights 做平方和。 第三种是加入 L1 正则化的表达，即把所有神经层的所有 weights 做绝对值的和。 接着定义梯度下降。</p>
<pre class="highlight"><code class="python"><span class="hljs-comment"># the way to compute cost</span>
<span class="hljs-comment"># cost = T.mean(T.square(l2.outputs - y))      # without regularization</span>
<span class="hljs-comment"># cost = T.mean(T.square(l2.outputs - y)) + 0.1 * ((l1.W ** 2).sum() + (l2.W ** 2).sum())  # with l2 regularization</span>
cost = T.mean(T.square(l2.outputs - y)) + <span class="hljs-number">0.1</span> * (abs(l1.W).sum() + abs(l2.W).sum())  <span class="hljs-comment"># with l1 regularization</span>

gW1, gb1, gW2, gb2 = T.grad(cost, [l1.W, l1.b, l2.W, l2.b])
</code></pre>
<h3 id="3-激活模型"><a class="markdownIt-Anchor" href="#3-激活模型"></a> 3. 激活模型</h3>
<p>定义学习率，训练函数等。</p>
<pre class="highlight"><code class="python">learning_rate = <span class="hljs-number">0.01</span>
train = theano.function(
    inputs=[x, y],
    updates=[(l1.W, l1.W - learning_rate * gW1),
             (l1.b, l1.b - learning_rate * gb1),
             (l2.W, l2.W - learning_rate * gW2),
             (l2.b, l2.b - learning_rate * gb2)])

compute_cost = theano.function(inputs=[x, y], outputs=cost)
</code></pre>
<h3 id="4-训练模型"><a class="markdownIt-Anchor" href="#4-训练模型"></a> 4. 训练模型</h3>
<pre class="highlight"><code class="python"><span class="hljs-comment"># record cost</span>
train_err_list = []
test_err_list = []
learning_time = []

<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1000</span>):
    train(x_train, y_train)
    <span class="hljs-keyword">if</span> i % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:
        <span class="hljs-comment"># record cost</span>
        train_err_list.append(compute_cost(x_train, y_train))
        test_err_list.append(compute_cost(x_test, y_test))
        learning_time.append(i)
</code></pre>
<h3 id="5-可视化结果"><a class="markdownIt-Anchor" href="#5-可视化结果"></a> 5. 可视化结果</h3>
<pre class="highlight"><code class="python"><span class="hljs-comment"># plot cost history</span>
plt.plot(learning_time, train_err_list, <span class="hljs-string">'r-'</span>)
plt.plot(learning_time, test_err_list, <span class="hljs-string">'b--'</span>)
plt.show()
</code></pre>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/articles/9049ed66/output_134_0.png" class="">
<h2 id="八-保存及提取模型"><a class="markdownIt-Anchor" href="#八-保存及提取模型"></a> 八、保存及提取模型</h2>
<pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> theano
<span class="hljs-keyword">import</span> theano.tensor <span class="hljs-keyword">as</span> T
<span class="hljs-keyword">import</span> pickle

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">compute_accuracy</span><span class="hljs-params">(y_target, y_predict)</span>:</span>
    correct_prediction = np.equal(y_predict, y_target)
    accuracy = np.sum(correct_prediction)/len(correct_prediction)
    <span class="hljs-keyword">return</span> accuracy

rng = np.random

<span class="hljs-comment"># set random seed</span>
np.random.seed(<span class="hljs-number">100</span>)

N = <span class="hljs-number">400</span>
feats = <span class="hljs-number">784</span>

<span class="hljs-comment"># generate a dataset: D = (input_values, target_class)</span>
D = (rng.randn(N, feats), rng.randint(size=N, low=<span class="hljs-number">0</span>, high=<span class="hljs-number">2</span>))

<span class="hljs-comment"># Declare Theano symbolic variables</span>
x = T.dmatrix(<span class="hljs-string">"x"</span>)
y = T.dvector(<span class="hljs-string">"y"</span>)

<span class="hljs-comment"># initialize the weights and biases</span>
w = theano.shared(rng.randn(feats), name=<span class="hljs-string">"w"</span>)
b = theano.shared(<span class="hljs-number">0.</span>, name=<span class="hljs-string">"b"</span>)

<span class="hljs-comment"># Construct Theano expression graph</span>
p_1 = <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + T.exp(-T.dot(x, w) - b))
prediction = p_1 &gt; <span class="hljs-number">0.5</span>
xent = -y * T.log(p_1) - (<span class="hljs-number">1</span>-y) * T.log(<span class="hljs-number">1</span>-p_1)
cost = xent.mean() + <span class="hljs-number">0.01</span> * (w ** <span class="hljs-number">2</span>).sum()
gw, gb = T.grad(cost, [w, b])

<span class="hljs-comment"># Compile</span>
learning_rate = <span class="hljs-number">0.1</span>
train = theano.function(
          inputs=[x, y],
          updates=((w, w - learning_rate * gw), (b, b - learning_rate * gb)))
predict = theano.function(inputs=[x], outputs=prediction)

<span class="hljs-comment"># Training</span>
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">500</span>):
    train(D[<span class="hljs-number">0</span>], D[<span class="hljs-number">1</span>])
</code></pre>
<pre><code>WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
</code></pre>
<h3 id="1-保存模型"><a class="markdownIt-Anchor" href="#1-保存模型"></a> 1. 保存模型</h3>
<p>把所有的参数放入 <code>save</code> 文件夹中，命名文件为 <code>model.pickle</code>，以 <code>wb</code> 的形式打开并把参数写入进去。</p>
<p>定义 <code>model＝[]</code> 用来保存 <code>weights</code> 和 <code>bias</code>，这里用的是 list 结构保存，也可以用字典结构保存，提取值时用 <code>get_value()</code> 命令。</p>
<p>再用 <code>pickle.dump</code> 把 model 保存在 file 中。</p>
<p>可以通过 <code>print(model[0][:10])</code> 打印出保存的 weights 的前 10 个数，方便后面提取模型时检查是否保存成功。还可以打印 accuracy 看准确率是否一样。</p>
<pre class="highlight"><code class="python"><span class="hljs-comment"># save model</span>
<span class="hljs-keyword">import</span> os

<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(<span class="hljs-string">'save'</span>):
      os.makedirs(<span class="hljs-string">'save'</span>)
<span class="hljs-keyword">with</span> open(<span class="hljs-string">'save/model.pickle'</span>, <span class="hljs-string">'wb'</span>) <span class="hljs-keyword">as</span> file:
    model = [w.get_value(), b.get_value()]
    pickle.dump(model, file)
    print(model[<span class="hljs-number">0</span>][:<span class="hljs-number">10</span>])
    print(<span class="hljs-string">"accuracy:"</span>, compute_accuracy(D[<span class="hljs-number">1</span>], predict(D[<span class="hljs-number">0</span>])))
</code></pre>
<pre><code>[-0.15707296  0.14590665 -0.08451091 -0.12594476 -0.13424085 -0.33887753
  0.12650858  0.20702686  0.0549835   0.29920542]
accuracy: 1.0
</code></pre>
<h3 id="2-提取模型"><a class="markdownIt-Anchor" href="#2-提取模型"></a> 2. 提取模型</h3>
<p>接下来提取模型时，提前把代码中 <code># Trainin</code>g 和 <code># save model</code> 两部分注释掉，即相当于只是通过 <code>创建数据－建立模型－激活模型</code> 构建好了新的模型结构，下面要通过调用存好的参数来进行预测。</p>
<p>以 rb 的形式读取 <code>model.pickle</code> 文件加载到 <code>model</code> 变量中去，</p>
<p>然后用 <code>set_value</code> 命令把 <code>model</code> 的第 0 位存进 w，第 1 位存进 b 中。</p>
<p>同样可以打印出 <code>weights</code> 的前 10 位和 <code>accuracy</code>，来对比之前的结果，可以发现结果完全一样。</p>
<pre class="highlight"><code class="python"><span class="hljs-comment"># load model</span>
<span class="hljs-keyword">with</span> open(<span class="hljs-string">'save/model.pickle'</span>, <span class="hljs-string">'rb'</span>) <span class="hljs-keyword">as</span> file:
    model = pickle.load(file)
    w.set_value(model[<span class="hljs-number">0</span>])
    b.set_value(model[<span class="hljs-number">1</span>])
    print(w.get_value()[:<span class="hljs-number">10</span>])
    print(<span class="hljs-string">"accuracy:"</span>, compute_accuracy(D[<span class="hljs-number">1</span>], predict(D[<span class="hljs-number">0</span>])))
</code></pre>
<pre><code>[-0.15707296  0.14590665 -0.08451091 -0.12594476 -0.13424085 -0.33887753
  0.12650858  0.20702686  0.0549835   0.29920542]
accuracy: 1.0
</code></pre>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%BD%AC%E8%BD%BD/">转载</a><a class="post-meta__tags" href="/tags/Theano/">Theano</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/lukeaust/blog/img/fairy.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button button--animated"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/img/wechat.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/articles/3caf811f.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="https://cdn.jsdelivr.net/gh/lukeaust/blog/img/dl.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">神经网络零碎知识点</div></div></a></div><div class="next-post pull-right"><a href="/articles/61179b00.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="https://cdn.jsdelivr.net/gh/lukeaust/blog/img/fairy.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Applying Sequence Mining for Outlier Detection in Process Mining</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/articles/e88ae413.html" title="Ubuntu全盘备份与恢复"><img class="cover" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="https://cdn.jsdelivr.net/gh/lukeaust/blog/img/fairy.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-11</div><div class="title">Ubuntu全盘备份与恢复</div></div></a></div><div><a href="/articles/54ccc14c.html" title="Ubuntu安装Tensorflow2"><img class="cover" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="https://cdn.jsdelivr.net/gh/lukeaust/blog/img/fairy.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-11</div><div class="title">Ubuntu安装Tensorflow2</div></div></a></div><div><a href="/articles/506b889.html" title="同步Ubuntu文件夹同步到百度云"><img class="cover" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="https://cdn.jsdelivr.net/gh/lukeaust/blog/img/fairy.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-12</div><div class="title">同步Ubuntu文件夹同步到百度云</div></div></a></div><div><a href="/articles/110aeb3a.html" title="Poll的笔记 - 转载"><img class="cover" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="https://cdn.jsdelivr.net/gh/lukeaust/blog/img/fairy.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-09-27</div><div class="title">Poll的笔记 - 转载</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">叶小白</div><div class="author-info__description">用智慧丈量人生</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">48</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">47</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/lukeaust"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/lukeaust" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/lukeaust@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">一入学术深似海</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80-%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95"><span class="toc-number">1.</span> <span class="toc-text"> 一、基本用法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C-function%E7%94%A8%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text"> 二、Function用法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%BF%80%E5%8A%B1%E6%B4%BB%E5%87%BD%E6%95%B0%E4%BE%8B%E5%AD%90activation-function"><span class="toc-number">2.1.</span> <span class="toc-text"> 1. 激励&#x2F;活函数例子(activation function)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%A4%9A%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%9A%84-function"><span class="toc-number">2.2.</span> <span class="toc-text"> 2. 多输入&#x2F;输出的 function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-function%E7%9A%84%E9%BB%98%E8%AE%A4%E5%80%BC%E5%8F%8A%E6%8C%87%E5%AE%9A%E5%8F%82%E6%95%B0%E5%90%8D"><span class="toc-number">2.3.</span> <span class="toc-text"> 3. function的默认值及指定参数名</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89-shared%E5%8F%98%E9%87%8F"><span class="toc-number">3.</span> <span class="toc-text"> 三、Shared变量</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%AE%9A%E4%B9%89shared%E5%8F%98%E9%87%8F"><span class="toc-number">3.1.</span> <span class="toc-text"> 1. 定义Shared变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%8F%90%E5%8F%96%E4%BD%BF%E7%94%A8"><span class="toc-number">3.2.</span> <span class="toc-text"> 2. 提取使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E4%B8%B4%E6%97%B6%E4%BD%BF%E7%94%A8"><span class="toc-number">3.3.</span> <span class="toc-text"> 3. 临时使用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B-layer%E7%B1%BB"><span class="toc-number">4.</span> <span class="toc-text"> 四、Layer类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%87%86%E5%A4%87"><span class="toc-number">4.1.</span> <span class="toc-text"> 1. 准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%AE%9A%E4%B9%89%E5%B1%82%E7%BB%93%E6%9E%84"><span class="toc-number">4.2.</span> <span class="toc-text"> 2. 定义层结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E7%BB%86%E8%8A%82%E8%AF%B4%E6%98%8E"><span class="toc-number">4.3.</span> <span class="toc-text"> 3. 细节说明</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94-%E5%9B%9E%E5%BD%92%E4%BE%8B%E5%AD%90regression"><span class="toc-number">5.</span> <span class="toc-text"> 五、回归例子Regression</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%AF%BC%E5%85%A5%E6%A8%A1%E5%9D%97"><span class="toc-number">5.1.</span> <span class="toc-text"> 1. 导入模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%AE%9A%E4%B9%89%E5%B1%82%E7%BB%93%E6%9E%84-2"><span class="toc-number">5.2.</span> <span class="toc-text"> 2. 定义层结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">5.3.</span> <span class="toc-text"> 3. 准备数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C"><span class="toc-number">5.4.</span> <span class="toc-text"> 4. 搭建网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">5.5.</span> <span class="toc-text"> 5. 开始训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">5.6.</span> <span class="toc-text"> 6. 可视化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD-%E5%88%86%E7%B1%BB%E5%AD%A6%E4%B9%A0"><span class="toc-number">6.</span> <span class="toc-text"> 六、分类学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%AF%BC%E5%85%A5%E6%A8%A1%E5%9D%97-2"><span class="toc-number">6.1.</span> <span class="toc-text"> 1. 导入模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0"><span class="toc-number">6.2.</span> <span class="toc-text"> 2. 定义函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86-2"><span class="toc-number">6.3.</span> <span class="toc-text"> 3. 准备数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%BB%BA%E7%AB%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.4.</span> <span class="toc-text"> 4. 建立模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E6%BF%80%E6%B4%BB%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.5.</span> <span class="toc-text"> 5. 激活模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.6.</span> <span class="toc-text"> 6. 训练模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83-%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">7.</span> <span class="toc-text"> 七、正则化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%AF%BC%E5%85%A5%E6%A8%A1%E5%9D%97%E5%B9%B6%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="toc-number">7.1.</span> <span class="toc-text"> 1. 导入模块并导入数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%BB%BA%E7%AB%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">7.2.</span> <span class="toc-text"> 2. 建立模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%BF%80%E6%B4%BB%E6%A8%A1%E5%9E%8B"><span class="toc-number">7.3.</span> <span class="toc-text"> 3. 激活模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">7.4.</span> <span class="toc-text"> 4. 训练模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%8F%AF%E8%A7%86%E5%8C%96%E7%BB%93%E6%9E%9C"><span class="toc-number">7.5.</span> <span class="toc-text"> 5. 可视化结果</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AB-%E4%BF%9D%E5%AD%98%E5%8F%8A%E6%8F%90%E5%8F%96%E6%A8%A1%E5%9E%8B"><span class="toc-number">8.</span> <span class="toc-text"> 八、保存及提取模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%BF%9D%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="toc-number">8.1.</span> <span class="toc-text"> 1. 保存模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%8F%90%E5%8F%96%E6%A8%A1%E5%9E%8B"><span class="toc-number">8.2.</span> <span class="toc-text"> 2. 提取模型</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/articles/a57c573c.html" title="从事件日志到目标"><img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="https://cdn.jsdelivr.net/gh/lukeaust/blog/img/fairy.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="从事件日志到目标"/></a><div class="content"><a class="title" href="/articles/a57c573c.html" title="从事件日志到目标">从事件日志到目标</a><time datetime="2021-06-29T08:17:57.735Z" title="发表于 2021-06-29 16:17:57">2021-06-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/articles/d737cada.html" title="无题"><img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="https://cdn.jsdelivr.net/gh/lukeaust/blog/img/fairy.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="无题"/></a><div class="content"><a class="title" href="/articles/d737cada.html" title="无题">无题</a><time datetime="2021-06-29T08:17:57.731Z" title="发表于 2021-06-29 16:17:57">2021-06-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/articles/aecffc40.html" title="论文题目"><img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="https://cdn.jsdelivr.net/gh/lukeaust/blog/img/fairy.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文题目"/></a><div class="content"><a class="title" href="/articles/aecffc40.html" title="论文题目">论文题目</a><time datetime="2021-06-29T08:17:57.619Z" title="发表于 2021-06-29 16:17:57">2021-06-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/articles/85537cbc.html" title="无题"><img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="https://cdn.jsdelivr.net/gh/lukeaust/blog/img/fairy.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="无题"/></a><div class="content"><a class="title" href="/articles/85537cbc.html" title="无题">无题</a><time datetime="2021-06-29T08:17:57.611Z" title="发表于 2021-06-29 16:17:57">2021-06-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/articles/110aeb3a.html" title="Poll的笔记 - 转载"><img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="https://cdn.jsdelivr.net/gh/lukeaust/blog/img/fairy.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Poll的笔记 - 转载"/></a><div class="content"><a class="title" href="/articles/110aeb3a.html" title="Poll的笔记 - 转载">Poll的笔记 - 转载</a><time datetime="2020-09-27T12:40:06.000Z" title="发表于 2020-09-27 20:40:06">2020-09-27</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2021 By 叶小白</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'Sa9Gr02xMinB8aMKhiaxPCsP-gzGzoHsz',
      appKey: 'Q99L5wMhgk70QnUTbJxiEcA5',
      placeholder: '记得留下你的昵称和邮箱....可以快速收到回复',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: true,
      path: window.location.pathname,
      requiredFields: ["nick"],
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>